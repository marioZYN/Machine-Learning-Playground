{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K近邻算法是一个无模型算法，只需要存储训练数据即可。当有新的数据进来需要预测类别时，我们从存储的数据中选择离新数据点最近的K个样本，采用多数投票的方法决定新数据的类别。\n",
    "\n",
    "K近邻法有三个决定因素：\n",
    "* 距离度量\n",
    "* K值选择\n",
    "* 分类决策规则\n",
    "\n",
    "一般而言，分类决策规则不会有什么变动，都是采用投票表决的方法。距离度量可以选择欧式距离和更一般的$L_p$距离。K值小的时候，模型更为复杂；K值大的时候，模型更为简单。K值的选择是近似误差和估计误差之间的一个取舍，通常可以用交叉验证法来选择最优的K值。\n",
    "\n",
    "K近邻算法性能的关键在于如何快速的找到近邻点。对于每一个需要预测的点，我们可以简单的线性遍历之前存储的样本，但是这样做的时间复杂度过高。KD树可以用来加速近邻点的搜索过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：\n",
    "https://www.cnblogs.com/eyeszjwang/articles/2429382.html  \n",
    "https://zhuanlan.zhihu.com/p/23966698"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,)\n"
     ]
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "class KNearestNeighbourhood:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        assert X.shape[0] == y.shape[0], \"shape error, there should be equal items in X and y\"\n",
    "        self.data = [(X[i], y[i]) for i in range(len(X))]\n",
    "    \n",
    "    def predict(self, x, metric='euclidean', K=5):\n",
    "        if metric == 'euclidean':\n",
    "            classes = self._nearestK(x, self._euclidean, K)\n",
    "        else:\n",
    "            assert False, metric + \" is not supported!\"\n",
    "        \n",
    "        # find the class with the highest occurance         \n",
    "        return Counter(classes).most_common(1)[0][0]\n",
    "    \n",
    "    def _nearestK(self, x, metric_func, K):\n",
    "        candidates = sorted(self.data, key=lambda t: metric_func(x, t[0]))[:K]\n",
    "        return [x[1] for x in candidates]\n",
    "    \n",
    "    def _euclidean(self, x1, x2):\n",
    "        return np.sqrt(np.sum((x1 - x2)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = KNearestNeighbourhood()\n",
    "a.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.predict([1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KDNode:\n",
    "    def __init__(self):\n",
    "        self.data_point = None # is a typle (ndarray, int) where ndarray is the features and int is the class\n",
    "        self.split_d = -1\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.parent = None\n",
    "\n",
    "class KDTree:\n",
    "    def __init__(self):\n",
    "        self.root = None\n",
    "    \n",
    "    def construct(self, dataset):\n",
    "        self.root = self._construct_rec(None, dataset, 0)\n",
    "        \n",
    "    def get_nearest_neighborhood(self, x, k=1, metric='euclidean'):\n",
    "        search_list = self.search_leaf(x)\n",
    "        neighbors = self.back_traverse(search_list, x, k, metric)\n",
    "        return neighbors\n",
    "        \n",
    "    def search_leaf(self, x):\n",
    "        search_list = []\n",
    "        node = self.root\n",
    "        while node:\n",
    "            search_list.append(node)\n",
    "            if node.left and not node.right:\n",
    "                node = node.left\n",
    "            elif node.right and not node.left:\n",
    "                node = node.right\n",
    "            elif not node.left and not node.right:\n",
    "                break\n",
    "            else:\n",
    "                x_v = x[node.split_d]\n",
    "                n_v = node.data_point[0][node.split_d]\n",
    "                if x_v <= n_v:\n",
    "                    node = node.left\n",
    "                else:\n",
    "                    node = node.right\n",
    "\n",
    "        return search_list\n",
    "    \n",
    "    def back_traverse(self, search_list, x, k=1, metric='euclidean'):\n",
    "        result = []\n",
    "        dist_stored = []\n",
    "        while search_list:\n",
    "            node = search_list.pop()\n",
    "            dist = self._distance(node.data_point[0], x, metric)\n",
    "            if len(result) < k:\n",
    "                result.append(node)\n",
    "                dist_stored.append(dist)\n",
    "            else:\n",
    "                MAX = max(dist_stored)\n",
    "                if dist < MAX:\n",
    "                    max_idx = dist_stored.index(MAX)\n",
    "                    result.pop(max_idx)\n",
    "                    dist_stored.pop(max_idx)\n",
    "                    result.append(node)\n",
    "                    dist_stored.append(dist)\n",
    "            # check if we need to tranverse the other part\n",
    "            h = abs(node.data_point[0][node.split_d] - x[node.split_d])\n",
    "            if min(dist_stored) > h:\n",
    "                # we need to traverse to the other part\n",
    "                if x[node.split_d] < node.data_point[0][node.split_d] and node.right:\n",
    "                    search_list.append(node.right)\n",
    "                elif x[node.split_d] > node.data_point[0][node.split_d] and node.left:\n",
    "                    search_list.append(node.left)\n",
    "        \n",
    "        return result\n",
    "                \n",
    "    \n",
    "    def _construct_rec(self, parent, dataset, depth):\n",
    "        if not dataset:\n",
    "            return None\n",
    "        node = KDNode()\n",
    "        node.parent = parent\n",
    "        dim = len(dataset[0][0]) # dimesion of feature space\n",
    "        node.split_d = depth % dim\n",
    "        dataset.sort(key=lambda x: x[0][node.split_d])\n",
    "        mid_idx = len(dataset) // 2\n",
    "        node.data_point = dataset[mid_idx]\n",
    "        node.left = self._construct_rec(node, dataset[:mid_idx], depth+1)\n",
    "        node.right = self._construct_rec(node, dataset[mid_idx+1:], depth+1)\n",
    "        \n",
    "        return node\n",
    "    \n",
    "    def _distance(self, x1, x2, metric='euclidean'):\n",
    "        if metric == 'euclidean':\n",
    "            return np.sum((x1 - x2)**2)\n",
    "        else:\n",
    "            assert False, metric + 'is not supported!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test KDTree\n",
    "test_X = [[7,2],[5,4],[9,6],[2,3],[4,7],[8,1]]\n",
    "test_X = [np.asarray(x) for x in test_X]\n",
    "test_y = [1,0,1,0,1,0]\n",
    "test_data = [(test_X[i], test_y[i]) for i in range(len(test_X))]\n",
    "\n",
    "tree = KDTree()\n",
    "tree.construct(test_data)\n",
    "# check KDTree construction\n",
    "assert np.array_equal(tree.root.right.left.data_point[0], np.array([8,1]))\n",
    "assert np.array_equal(tree.root.left.right.data_point[0], np.array([4,7]))\n",
    "\n",
    "# check 1 Nearest Neightbourhood\n",
    "l = tree.get_nearest_neighborhood(np.array([2.1, 3.1]), 1)\n",
    "assert np.array_equal(l[0].data_point[0], np.array([2, 3]))\n",
    "l = tree.get_nearest_neighborhood(np.array([2, 4.5]), 1)\n",
    "assert np.array_equal(l[0].data_point[0], np.array([2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestNeighbourhoodKDTree:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.tree = KDTree()\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        assert X.shape[0] == y.shape[0], \"shape error, there should be equal items in X and y\"\n",
    "        self.data = [(X[i], y[i]) for i in range(len(X))]\n",
    "        self.tree.construct(self.data)\n",
    "    \n",
    "    def predict(self, x, metric='euclidean', K=5):\n",
    "        if metric == 'euclidean':\n",
    "            classes = self._nearestK(x, metric, K)\n",
    "        else:\n",
    "            assert False, metric + \" is not supported!\"\n",
    "        \n",
    "        # find the class with the highest occurance         \n",
    "        return Counter(classes).most_common(1)[0][0]\n",
    "    \n",
    "    def _nearestK(self, x, metric, K):\n",
    "        candidates = self.tree.get_nearest_neighborhood(x, K, metric)\n",
    "        return [x.data_point[1] for x in candidates]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = KNearestNeighbourhoodKDTree()\n",
    "b.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert a.predict(np.array([1,1,1,1])) == b.predict(np.array([1,1,1,1]))\n",
    "assert a.predict(np.array([1,12,1,2])) == b.predict(np.array([1,12,1,2]))\n",
    "assert a.predict(np.array([1,1,1,1.3])) == b.predict(np.array([1,1,1,1.3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.predict(np.array([1,1,1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.predict(np.array([1,1,1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
